{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European past floods\n",
    "\n",
    "In this notebook, we analyze a dataset on past floods in Europe: <https://www.eea.europa.eu/data-and-maps/data/european-past-floods> ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the documentation\n",
    "This dataset is quite well documented, which is noteworthy as it is not always the case.\n",
    "I strongly encourage you to take a few minutes to carefully read the documentation on the landing page, in this instance :\n",
    "- description,\n",
    "- table definition,\n",
    "- metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reading should enable you to answer a set of common, basic questions that will help guide your analysis, such as :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Who created this dataset and for what purpose ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How was the dataset created ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do the instances that comprise the dataset represent (eg. people, companies, events, photos...) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What data does each instance consist of ? Are they \"raw\" data or (computed) features ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are the instances related in some way ? If so, are there specific fields that enable cross-reference ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for a dataset is always written with some purpose, for an intended type of reader, in a certain context, hence it is very likely that you will not find all the answers in the documentation.\n",
    "\n",
    "Equipped with this knowledge, you can start the exploratory analysis of the data to gather the missing information to complete your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis\n",
    "First, you need to retrieve the dataset :\n",
    "1. Download the dataset exported as a zip file containing a **set of CSV files**,\n",
    "2. Extract the CSV files to a folder. This folder can be anywhere you like, provided you can easily retrieve its path. The simplest and least confusing solution might be to store your data next to your notebook (eg. create a `data` folder in the same directory as this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start exploring the dataset with [pandas](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular information\n",
    "Read the CSV file `floodphenomena.csv` with the `read_csv` function.\n",
    "The data will be read into a pandas DataFrame, see the [pandas intro tutorial 01](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB : you most certainly need to change the path to the file\n",
    "df = pd.read_csv('../data/FloodPhenomena_2015_public_csv/floodphenomena.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the DataFrame by typing its name.\n",
    "By default pandas displays the column headers, the first and last five rows with their row index (at the left end of the row in **bold**), the total number of rows and columns (below the last line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc</th>\n",
       "      <th>FloodPhenomenaID</th>\n",
       "      <th>Year</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Number_FE</th>\n",
       "      <th>Number_FL</th>\n",
       "      <th>EUUOMCODE</th>\n",
       "      <th>FP_Severity</th>\n",
       "      <th>FP_Duration</th>\n",
       "      <th>FP_Extension</th>\n",
       "      <th>SourceOfFlooding</th>\n",
       "      <th>CharacteristicsOfFlooding</th>\n",
       "      <th>MechanismOfFlooding</th>\n",
       "      <th>FrequencyCategory</th>\n",
       "      <th>Area</th>\n",
       "      <th>Source</th>\n",
       "      <th>OtherSources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL-1992-11-17</td>\n",
       "      <td>1992</td>\n",
       "      <td>17/11/1992</td>\n",
       "      <td>19/11/1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EM-DAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL-1995-08-19</td>\n",
       "      <td>1995</td>\n",
       "      <td>19/08/1995</td>\n",
       "      <td>26/08/1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DFO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL-1995-09-20</td>\n",
       "      <td>1995</td>\n",
       "      <td>20/09/1995</td>\n",
       "      <td>20/09/1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EM-DAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL-1995-09-21</td>\n",
       "      <td>1995</td>\n",
       "      <td>21/09/1995</td>\n",
       "      <td>24/09/1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DFO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>AL-1995-12-27</td>\n",
       "      <td>1995</td>\n",
       "      <td>27/12/1995</td>\n",
       "      <td>27/12/1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EM-DAT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>XK</td>\n",
       "      <td>XK-2008-04-10</td>\n",
       "      <td>2008</td>\n",
       "      <td>10/04/2008</td>\n",
       "      <td>15/04/2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequent</td>\n",
       "      <td>20.0</td>\n",
       "      <td>National Authorities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>XK</td>\n",
       "      <td>XK-2010-01-07</td>\n",
       "      <td>2010</td>\n",
       "      <td>07/01/2010</td>\n",
       "      <td>12/01/2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rare</td>\n",
       "      <td>8.0</td>\n",
       "      <td>National Authorities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>XK</td>\n",
       "      <td>XK-2013-03-14</td>\n",
       "      <td>2013</td>\n",
       "      <td>14/03/2013</td>\n",
       "      <td>20/03/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequent</td>\n",
       "      <td>10.0</td>\n",
       "      <td>National Authorities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3693</th>\n",
       "      <td>XK</td>\n",
       "      <td>XK-2014-04-19</td>\n",
       "      <td>2014</td>\n",
       "      <td>19/04/2014</td>\n",
       "      <td>23/04/2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Regional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rare</td>\n",
       "      <td>30.0</td>\n",
       "      <td>National Authorities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>XK</td>\n",
       "      <td>XK-2015-02-05</td>\n",
       "      <td>2015</td>\n",
       "      <td>05/02/2015</td>\n",
       "      <td>12/02/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very High</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Frequent</td>\n",
       "      <td>46.5</td>\n",
       "      <td>National Authorities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3695 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cc FloodPhenomenaID  Year   StartDate     EndDate  Number_FE  Number_FL  \\\n",
       "0     AL    AL-1992-11-17  1992  17/11/1992  19/11/1992        NaN        NaN   \n",
       "1     AL    AL-1995-08-19  1995  19/08/1995  26/08/1995        NaN        NaN   \n",
       "2     AL    AL-1995-09-20  1995  20/09/1995  20/09/1995        NaN        NaN   \n",
       "3     AL    AL-1995-09-21  1995  21/09/1995  24/09/1995        NaN        NaN   \n",
       "4     AL    AL-1995-12-27  1995  27/12/1995  27/12/1995        NaN        NaN   \n",
       "...   ..              ...   ...         ...         ...        ...        ...   \n",
       "3690  XK    XK-2008-04-10  2008  10/04/2008  15/04/2008        NaN        NaN   \n",
       "3691  XK    XK-2010-01-07  2010  07/01/2010  12/01/2010        NaN        NaN   \n",
       "3692  XK    XK-2013-03-14  2013  14/03/2013  20/03/2013        NaN        NaN   \n",
       "3693  XK    XK-2014-04-19  2014  19/04/2014  23/04/2014        NaN        NaN   \n",
       "3694  XK    XK-2015-02-05  2015  05/02/2015  12/02/2015        NaN        NaN   \n",
       "\n",
       "     EUUOMCODE FP_Severity  FP_Duration FP_Extension SourceOfFlooding  \\\n",
       "0          NaN   Very High          2.0          NaN              NaN   \n",
       "1          NaN   Very High          8.0          NaN              NaN   \n",
       "2          NaN   Very High          NaN          NaN              NaN   \n",
       "3          NaN   Very High          4.0          NaN              NaN   \n",
       "4          NaN    Moderate          NaN          NaN              NaN   \n",
       "...        ...         ...          ...          ...              ...   \n",
       "3690       NaN    Moderate          5.0        Local              NaN   \n",
       "3691       NaN   Very High          5.0     Regional              NaN   \n",
       "3692       NaN        High          6.0        Local              NaN   \n",
       "3693       NaN        High          4.0     Regional              NaN   \n",
       "3694       NaN   Very High          7.0        Local              NaN   \n",
       "\n",
       "     CharacteristicsOfFlooding MechanismOfFlooding FrequencyCategory  Area  \\\n",
       "0                          NaN                 NaN               NaN   NaN   \n",
       "1                          NaN                 NaN               NaN   NaN   \n",
       "2                          NaN                 NaN               NaN   NaN   \n",
       "3                          NaN                 NaN               NaN   NaN   \n",
       "4                          NaN                 NaN               NaN   NaN   \n",
       "...                        ...                 ...               ...   ...   \n",
       "3690                       NaN                 NaN          Frequent  20.0   \n",
       "3691                       NaN                 NaN              Rare   8.0   \n",
       "3692                       NaN                 NaN          Frequent  10.0   \n",
       "3693                       NaN                 NaN              Rare  30.0   \n",
       "3694                       NaN                 NaN          Frequent  46.5   \n",
       "\n",
       "                    Source OtherSources  \n",
       "0                   EM-DAT          NaN  \n",
       "1                      DFO          NaN  \n",
       "2                   EM-DAT          NaN  \n",
       "3                      DFO          NaN  \n",
       "4                   EM-DAT          NaN  \n",
       "...                    ...          ...  \n",
       "3690  National Authorities          NaN  \n",
       "3691  National Authorities          NaN  \n",
       "3692  National Authorities          NaN  \n",
       "3693  National Authorities          NaN  \n",
       "3694  National Authorities          NaN  \n",
       "\n",
       "[3695 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the data table\n",
    "We can display a summary of the DataFrame with `info()`, including for each column its index, name, number of non-null values, and data type (`dtype`).\n",
    "For more information, you can read the [pandas intro tutorial 02](https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3695 entries, 0 to 3694\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   cc                         3695 non-null   object \n",
      " 1   FloodPhenomenaID           3695 non-null   object \n",
      " 2   Year                       3695 non-null   int64  \n",
      " 3   StartDate                  2268 non-null   object \n",
      " 4   EndDate                    2246 non-null   object \n",
      " 5   Number_FE                  3271 non-null   float64\n",
      " 6   Number_FL                  2823 non-null   float64\n",
      " 7   EUUOMCODE                  2798 non-null   object \n",
      " 8   FP_Severity                3695 non-null   object \n",
      " 9   FP_Duration                2244 non-null   float64\n",
      " 10  FP_Extension               132 non-null    object \n",
      " 11  SourceOfFlooding           2636 non-null   object \n",
      " 12  CharacteristicsOfFlooding  1050 non-null   object \n",
      " 13  MechanismOfFlooding        1431 non-null   object \n",
      " 14  FrequencyCategory          788 non-null    object \n",
      " 15  Area                       580 non-null    float64\n",
      " 16  Source                     3695 non-null   object \n",
      " 17  OtherSources               95 non-null     object \n",
      "dtypes: float64(4), int64(1), object(13)\n",
      "memory usage: 519.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`info` also displays the memory usage of the DataFrame.\n",
    "\n",
    "How does it compare to the file size on disk ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting subsets\n",
    "\n",
    "One of the fundamental operations on DataFrames is to be able to filter the dataset on a certain condition, to keep only certain rows or columns.\n",
    "\n",
    "The basic operators for selection are square brackets `[]`, `loc` and `iloc`, and you can select rows or columns by their position or label, or with a conditional expression on values, see the [pandas intro tutorial 03](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html).\n",
    "\n",
    "Choose a European country present in the dataset and\n",
    "\n",
    "* filter rows corresponding to the flood events that happened in that country,\n",
    "* filter columns to keep only the country, phenomena id, year, start and end date, severity and duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data\n",
    "\n",
    "You can create plots from a DataFrame easily using pandas' integration of matplotlib, see the [pandas intro tutorial 04](https://pandas.pydata.org/docs/getting_started/intro_tutorials/04_plotting.html).\n",
    "\n",
    "Create plots to visualize different columns (try to come up with different types of plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "You can compute various summary statistics that depend on the type of variable in each column, see the [pandas intro tutorial 06](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html).\n",
    "\n",
    "Compute summary statistics for several columns from different types, and combinations of columns that could provide interesting insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting data\n",
    "The entries are sorted by country, but it would make sense to try a different order and sort by date, see the [pandas intro tutorial 07](https://pandas.pydata.org/docs/getting_started/intro_tutorials/07_reshape_table_layout.html).\n",
    "\n",
    "Sort entries by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns and combining data from different tables\n",
    "\n",
    "The DataFrame contains country codes, which are not great for the uninformed reader.\n",
    "\n",
    "Luckily, another CSV file in the dataset contains a list of country codes and names.\n",
    "\n",
    "Find the relevant file and read it into another DataFrame, using `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second table enables you to map country codes to country names, see the [pandas intro tutorial 08](https://pandas.pydata.org/docs/getting_started/intro_tutorials/08_combine_dataframes.html).\n",
    "\n",
    "You can rename columns, see the [pandas intro tutorial 05](https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html).\n",
    "\n",
    "Add a column with country names to the first DataFrame, and name it `country_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with dates\n",
    "pandas has a specific data type for dates. You can explicitly ask pandas to use this type for specific columns, either during `read_csv` or after, see the [pandas intro tutorial 09](https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html).\n",
    "\n",
    "Convert columns `StartDate` and `EndDate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This specific data type makes it easy to filter floods by month, or to know what day of the week it happened on, or to compute the time between any two floods in Europe or within a given country.\n",
    "\n",
    "Draw one of these plots (or any other interesting one that relies on processing dates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with textual data\n",
    "Another CSV file in the dataset contains the event locations of the floods.\n",
    "\n",
    "pandas provides a number of functions to process text strings, see the [pandas intro tutorial 10](https://pandas.pydata.org/docs/getting_started/intro_tutorials/10_text_data.html).\n",
    "\n",
    "Read the event locations in another DataFrame and search all event locations that mention the \"Danube\" river in English or \"Donau\" in German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding remarks\n",
    "This dataset is informative and useful to answer certain questions but it is only scratching the surface of the current state of data collection on floods.\n",
    "Much more detailed and precise data are collected to enable fine-grained analysis and prediction, see for example :\n",
    "<https://www.eea.europa.eu/data-and-maps/indicators/river-floods-3/assessment> ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
