{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction : Principal Component Analysis\n",
    "\n",
    "As the dimensionality of a dataset grows, it is often the case that some features are correlated.\n",
    "Correlated features can hinder the human analyst but they are also a factor of confusion and inefficacy during the training of machine learning models.\n",
    "\n",
    "A number of techniques exist that explicit aim at reducing the dimensionality of datasets.\n",
    "They can be used by a human analyst for an exploratory data analysis, or as a pre- or post-processing step in a data science or machine learning pipeline, or as an initialization technique for costly machine learning methods.\n",
    "We will start with a classic and intuitive method : [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "The [scikit-learn machine learning library](https://scikit-learn.org) provides an [implementation of PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), along with a number of variants. You can read more about the implementation of PCA and its variants in the [scikit-learn user guide](https://scikit-learn.org/stable/modules/decomposition.html#pca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset as a pandas DataFrame (\"as_frame=True\")\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)\n",
    "# assign the feature matrix and target vector to variables\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reduce the dataset to a 3-dimension space, where we can create visualizations as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# create a PCA model that will map the input data to 3 dimensions\n",
    "pca = PCA(n_components=3)\n",
    "# compute the PCA for the feature matrix X\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 principal components are stored in `pca.components_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display the 3 principal components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is each of these 3 components mathematically ? What types of mathematical objects are they ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of variance explained by each of the components is stored in `pca.explained_variance_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display the explained variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually more immediately useful to display the percentage of variance explained by each of the selected components:\n",
    "- The first principal components explain the maximum of variance. Knowing how much of the variance they explain is useful to decide how many principal components we need to keep if we want to compress the data to preserve a given total percentage of the variance of the data (eg. 2 components might explain more than 90% of the variance, and it is enough for your needs).\n",
    "- The last principal components explain less variance, but sometimes they are the most interesting because they capture the variance that corresponds to subtle differences between otherwise very similar target classes.\n",
    "The percentage of variance is stored in `pca.explained_variance_ratio_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display the explained variance ratios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Principal Component Analysis object `pca`, fit on the feature matrix `X`, can transform each feature vector `X_i` from 4 dimensions to a reduced `X_r_i` in 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the first two samples with their PCA reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display the first two feature vectors in X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO display the first two feature vectors in X_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `X_r` is quite different from `X` but it might be clearer with plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the PCA\n",
    "We can plot the samples in the reduced feature space, just as we did in the original feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the samples on each pair of dimensions in the PCA reduced feature space (pair plots for `X_r` and `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create the pair plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the samples in the 3 dimensions of the PCA reduced feature space, in a 3d plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create the 3d plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the plots in the reduced feature space compare to the plots in the original feature space ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
