---
title: "Data"
subtitle: "Open, Big, etc"
author: "Mathieu Morey"
date: "2020-09-14"
output:
  SlidesDatactivist::moon_reader:
    seal: false
    css: [default, datactivist, datactivist-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
params:
  event: "MScT CSE - CSDS"
  slug: data-open-big-etc/
---

class: center, middle
background-position: 50% 50%

# Data
## Open, Big, etc
<BR><BR><BR>
## Mathieu Morey, Datactivist
### mathieu@datactivist.coop

### 2020-09-14
---

class: center, middle

These slides online : `r paste0("http://moreymat.github.io/", params$slug)`

Sources : `r paste0("https://github.com/moreymat/ecm-cse-csds/", params$slug)`

Adapted from original content by Samuel Go√´ta and Jo√´l Gombin (Datactivist).
Productions by Datactivist are freely reusable under the terms of the [Creative Commons 4.0 BY-SA](https://creativecommons.org/licenses/by-sa/4.0/legalcode.fr) license.

<BR>
<BR>

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-sa.png)


---
## Datactivist : Who we are

<BR><BR><BR><BR>

[![](https://github.com/datactivist/slides_datactivist/raw/master/inst/rmarkdown/templates/xaringan/resources/img/logo.png)](https://datactivist.coop)

### We .red[open data], we make them .red[useful]

---
## Datactivist : Who we are


![](https://datactivist.coop/images/photo-equipe.jpg)

---
## Datactivist : Who we are

- Datactivist is a .red[**pure player in open data**] launched in 2016, by Samuel Go√´ta et Jo√´l Gombin.

<!-- TODO translate  -->
- We work on .red[**all the steps in the process of opening data**], with data producers and re-users.

- We apply to ourselves our own .red[**values**] : we are a worker cooperative ; our training material and content are freely reusable, published under a Creative Commons license.

- Our approach stems from research, see **https://datactivist.coop/these**. 

- We host and run the [#TeamOpenData](https://teamopendata.org) community on (mostly French) open data.

---
## Datactivist : What we do

- Consulting on .red[**strategies to open data**] : we help organisations in designing and implementing their strategy to open data.


- .red[**Assisting the reuse of open data**] : we help organisations to use data in their daily operations. 

- .red[**Raising awareness and training on data**] : we teach data literacy, the general principles and best practices of open data, and introduce to data science. 

- .red[**Data facilitation**] : we host and run hackathons, open data camps, data expeditions...

???

La m√©diation de donn√©es est aussi fondamentalement une animation de communaut√©(s). 

---
class:middle, center
## Warm up : 5 minutes, 20 data points

You have 5 minutes.

You must find 20 data points in your immediate surroundings.

(You cannot use any electronic device)

.footnote[[source](http://infolabs.io/5-minutes-20-donnees)]

---
class:center,inverse, middle
# What is a data point ?
---
class:center,inverse, middle
# According to you... ?
---
# The Roman censor, ancestor of statistics
.reduite3[![](img/asterix.png)]

.footnote[Source : *Asterix chez les pictes*, ¬© Albert Ren√© 2013]
---
# The Roman censor, ancestor of statistics
.reduite3[![](img/asterix1.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]
---
## Statistics : government and proof
.pull-left[.middle[Statistics is simultaneously :

  + **mean of government** (_Statistik_ - 18th century), and
  
  + **tool of proof** (_statistics_ - 19e si√®cle)]]
.pull-right[.reduite[![center](./img/desrosieres1.jpg)]]
---
  
## [Quantifying is defining then measuring](https://www.pressesdesmines.com/wp-content/uploads/2011/01/PourSocioHistExtr.pdf)

.pull-left[
> The verb "quantify" is used here in a broad sense : **express and bring to existence
numerically what used to be expressed by words and not numbers**.
]

.pull-right[![ ](img/desrosi.jpeg)]

---
## [Quantifying is defining then measuring](https://www.pressesdesmines.com/wp-content/uploads/2011/01/PourSocioHistExtr.pdf)

.middle.reduite3[![](img/asterix2.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]

---
## Quantifying is inscribing and freezing a reality in constant motion
.reduite2[![](img/asterix3.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]

---
## Etymology

### Latin : _dare_ (give) > _datum_ (given) > _data_ (given (pl.))
<br/><br/>
What is obvious, given, accepted without discussion

<br/><br/>

> From its first vernacular formulation, the existence of a datum has been independent of any
consideration of corresponding ontological truth. When a fact is proven false, it ceases
to be a fact. False data is data nonetheless.

.footnote[[Rosenberg, 2013](https://mitpress.mit.edu/books/raw-data-oxymoron)]

---
## Usage of "data"

The modern meaning appears at the end of the 18th century. 

Refers to experiments, acquisition of elements.

.reduite[![](img/data.png)]

---
## ‚ÄúDatafication‚Äù : turning the world into data
<!-- TODO find the original quotation? -->
> ‚ÄúL'immense gisement de donn√©es num√©riques d√©coule de la capacit√© √† param√©trer des aspects du monde et de la vie humaine qui n'avaient encore jamais √©t√© quantifi√©s. On peut qualifier ce processus de **¬´ mise en donn√©es ¬ª (datafication)**. 

> [‚Ä¶] ‚ÄúLa mise en donn√©es d√©signe autre chose que la num√©risation, laquelle consiste √† traduire un contenu analogique - texte, film, photographie - en une s√©quence de 1 et de 0 lisible par un ordinateur. Elle se r√©f√®re √† une action bien plus vaste, et aux implications encore insoup√ßonn√©es : **num√©riser non plus des documents, mais tous les aspects de la vie**.‚Äù

.footnote[[Kenneth Cukier, ‚ÄúMise en donn√©es du monde, le d√©luge num√©rique‚Äù](https://www.monde-diplomatique.fr/2013/07/CUKIER/49318)]
---

## "Digitisation" of the world
<!-- TODO translate -->
.pull-left[![](https://cefres.hypotheses.org/files/2017/06/couv_REY.jpg)]
.pull-right[
> La num√©risation ne serait pas survenue sans une "nombrification" pr√©alable qui consiste √† quantifier de plus en plus d'aspects de notre exp√©rience du r√©el.


> **Au commencement √©tait le verbe, il semble √† la fin que tout devient nombre.**


> Personne ne saurait parler s√©rieusement de l'√©tat de la soci√©t√© et discuter politique sans se r√©f√©rer aux informations quantitatives. ]

---
## The new data positivism

> *If you asked me to describe the rising philosophy of the day, I‚Äôd say it is **data-ism**. 
We now have the ability to gather huge amounts of data. 
This ability seems to carry with it certain cultural assumptions ‚Äî that everything that can be measured should be measured; that data is a transparent and reliable lens that allows us to filter out emotionalism and ideology; that data will help us do remarkable things ‚Äî like foretell the future.*


Jeff Brookes, √©ditorialiste du New York Times

---
## The roots of datafication of the world

.pull-left[
- Contact, in California in the 1960s, between the New Left and the New Communalists in a context of LSD and military research

- The inspiration of cybernetics (N. Wiener) : technical objects and human beings are part of a common sociotechnical system, regulated by information

- Example of Steward Brand, founder of the _Whole Earth Catalog_ then Wired => ["Forest Gump of the Internet"](https://questionsdecommunication.revues.org/8619)]
.pull-right[![](./img/wholeearthcatalog.jpg)]

---
## "Raw data" is an oxymoron

.pull-left[
> Data are always already ‚Äúcooked‚Äù and never entirely ‚Äúraw.‚Äù

> Data need to be imagined _as_ data to exist and function as such, and the imagination of data entails an interpretive base.

]
.pull-right[![](https://mitpress.mit.edu/sites/default/files/styles/large_book_cover/http/mitp-content-server.mit.edu%3A18180/books/covers/cover/%3Fcollid%3Dbooks_covers_0%26isbn%3D9780262518284%26type%3D.jpg?itok=PQI0SkzN)]
.footnote[[Source](https://mitpress.mit.edu/books/raw-data-oxymoron)]

---
class:inverse, middle, center
# Towards a definition of data
---

## The Data-Information-Knowledge-Wisdom pyramid

.pull-left[[![largeur](./img/DIKW_Pyramid.svg)](https://commons.wikimedia.org/w/index.php?curid=37705247)]

.pull-right[Attributed to [Russell Ackoff](http://en.wikipedia.org/wiki/Russell_L._Ackoff), 1989

Data can be :

- facts
- signals/stimuli
- symbols]

---
## Towards a definition of data

.pull-left.reduite2[![](img/kitchin.jpg)]
.pull-right[
> *Data are commonly understood to be the raw material produced by **abstracting the world** into categories, measures and other representational forms ‚Äì numbers, characters, symbols, images, sounds, electromagnetic waves, bits ‚Äì that constitute the **building blocks** from which information and knowledge are created.*

‚è∫ recordability

üèó> *buildings blocks*
]

---
class:middle
## Data or capta ?

> *Technically, then, what we understand as data are actually **capta** (derived from the Latin capere, meaning ‚Äòto take‚Äô); those units of data that have been selected and harvested from the sum of all potential data.*

[Kitchin, 2014](https://books.google.fr/books?hl=fr&lr=&id=GfOICwAAQBAJ&oi=fnd&pg=PP1&dq=kitchin+data+revolution&ots=pcyfMTZh-V&sig=dQyPTL3AIN_4RdWvtBFw4VjdAa4#v=onepage&q=kitchin%20data%20revolution&f=false)

---
class:middle
## Given or obtained ? 


> ¬´ Really, one should never talk about ‚Äúdata‚Äù, but rather of ‚Äúobtained‚Äù. ¬ª 

Bruno Latour, 1993

---

class:center, middle, inverse
## Data, data... what data ?

---
## Statistical data

.pull-left[
Different types of variables : 

- quantitative: notion of size or measurement
  * discrete vs continuous

- qualitative: notion of categories
  * nominal : named categories (maried / single / divorced / widow)
  * ordinal : named categories with an intrinsic ordering (weak / medium / strong)
  * intervals : ordered categories whose successive values are separated by identical intervals (12-16¬∞C / 16-20¬∞C / 20-24¬∞C ‚Ä¶)

]
.pull-right[![](img/spread.png)]

---
## Data 
.pull-left[
Non numeric (directly): text, image, video, audio...

  + can be converted to quantitative data

  + risk of losing the wealth, detail, precision... of the original data
  
  + qualitative data analysis
  
]
.pull-right[![](img/text_mining_intro_2.png)]

---
## Example : annotations for text mining

.reduite[![](img/annotation.png)]

---
## Structured data

.pull-left[
Data endowed with a model that defines the relations between the elements of the database

  + Ex : SQL relational database
  
  + Machine readable
  
  + Easy to analyse, process, visualise...
]
.pull-right[![](img/sql.jpeg)]

---
## Semi-structured data
.pull-left[
No pre-defined model : the structure is irregular, implicit... but the data is still organized, with a reasonable set of fields

Example : XML, JSON

Data can be sorted, ordered and structured
]
.pull-right[![](img/OCDSjson.jpg)]

---
## Unstructured data

.pull-left[
* No common, identifiable structure
* Ex : NoSQL database, logs
* Usually qualitative
* Hard to combine ou analyse in a quantitative manner

Unstructured data are believed to grow 15x faster than structured data
 
Machine learning more and more capable of analysing this data.]
.pull-right[![](img/structured-vs-unstructured-data.png)]

---
## Data : captured, escaped, transitory 

** Captured data **

Observation, survey, experiment, notes, sensors... => intention of generating data

** Escaped data**

By-product of an engine or system whose main function is different

** Transitory data**

Escaped data that are never examined, transformed or analysed


---
## Derived data

Result from processing or further analysis of captured data 

Example : [data from Google Maps](https://www.justinobeirne.com/google-maps-moat) : 


![](https://static1.squarespace.com/static/54ff63f0e4b0bafce6932642/t/5a383fdb41920241ebce859d/1513635810327/3-1+-+Making+AOIs.gif?format=1500w)

---
## Derived data

.reduite2[![](./img/nasa.jpg)]
---
## Indices, attributes, metadata

**Indices**

Data enabling to identify and relate. Essential to enrich data

**Attributes**

Data representing aspects of a phenomenon, but that are not indices (not unique identifiers)

**Metadata**

Data on data. Can be descriptive, structural ou administrative. Standard : Dublin Core. 

---
## Crowdsourced data
.pull-left[Des donn√©es produites par des citoyens, des communs partag√©s et gouvern√©s par leurs producteurs

Exemple : [OpenStreetMap](https://www.openstreetmap.org/query?lat=43.52367&lon=5.43256), le wiki de la carte]
.pull-right[.reduite[![](img/osm.png)]]

---
class:inverse, middle, center
# De l'open data au big data

---
## Big data
![](http://www.usine-digitale.fr/mediatheque/0/3/5/000351530/big-data.jpg)


---
## L'obsession du volume de donn√©es

.pull-left[
**Quelques chiffres omnipr√©sents** : 
- le volume de donn√©es produit double tous les 3 ans (Gantz & Reisel 2011)
- 90% des donn√©es cr√©√©es dans les deux derni√®res ann√©es (IBM 2012)
- 40% : croissance annuelle de la production de donn√©es (Maniyka et al. 2011)
]
.pull-right[![](img/whybig.png)]

---
## L'obsession du volume de donn√©es

**Probl√®mes de cette approche** : 
- Estimations guid√©es par des int√©r√™ts commerciaux
- Ne d√©finit pas ce que sont ces donn√©es
- R√©sume le big data au Volume
- Explique mal la mise en donn√©es du monde

---
## Les promesses du big data

Kitchin (2014) r√©sume les promesses du big data : 
- **‚ÄúGoverning people‚Äù** : dans la continuit√© de la statistique, am√©liorer la connaissance de l‚Äôadministration et pr√©dire les crimes

- **‚ÄúManaging organisations‚Äù** : am√©liorer le fonctionnement de toutes les composantes de l‚Äôorganisation par l‚Äôexploitation des donn√©es

- **‚ÄúLeveraging value and producing capital‚Äù** : micro-ciblage marketing, optimisation des magasins et des op√©rations, efficience de la chaine

- **‚ÄúCreating Better places‚Äù** : gouverner les villes avec des donn√©es (smart city) 

- **Un nouveau paradigme scientifique** : une nouvelle √®re guid√©e par les corr√©lations

---
## Linked data
.pull-left[
* pouss√© par W3C et Tim Berners-Lee
* Web s√©mantique / web des donn√©es
* RDF / SPARQL
* wikidata => http://projetjourdain.org/network/index.html
]
.pull-right[![](http://linkeddata.org/static/images/lod-datasets_2009-07-14_cropped.png)]

---
[![](img/histro.png)](http://histropedia.com/timeline/3jrttpg9bg0t/Google)

---
## API
.pull-left[
- Application Programming Interface => un programme vu de la surface

- les machines parlent aux machines

- donn√©e dynamique => ouverture potentiellement limit√©e et contr√¥l√©e 

- un exemple : [overpass turbo](https://overpass-turbo.eu/)]
.pull-right[![](https://d1avok0lzls2w.cloudfront.net/img_uploads/apis-for-marketers.png)]

---
class: middle, center

# Partie 2 : 
# ouvrir la boite noire de la data science

---
class:middle
## Programme

- Qu'est-ce que la data science ?
- Le data pipeline : acqu√©rir les donn√©es, les v√©rifier, les nettoyer, les analyser, les pr√©senter

---
class:middle
## Bonus

- Data visualisation : quel format et quel outil choisir pour quelle fonction ?
- Mod√©liser pour pr√©dire : introduction au machine learning et deep learning

---
class: middle, center, inverse

# Qu'est-ce que la data science ?

---
## Au commencement √©tait la statistique

- une vieille science (18e si√®cle), pour aider les √âtats (_Statistik_) mais aussi des entreprises priv√©es (au d√©part, les assureurs => actuariat)

- fond√©e sur les probabilit√©s

- faite par des math√©maticiens

- forte dimension th√©orique

---
## Au commencement √©tait la statistique

<iframe src="http://giphy.com/embed/9ADoZQgs0tyww" width="100%" height="450" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="http://giphy.com/gifs/obama-awesome-statistics-9ADoZQgs0tyww">via GIPHY</a></p>

---
## Au commencement √©tait la statistique

> I keep saying the sexy job in the next ten years will be statisticians. People think I‚Äôm joking, but who would‚Äôve guessed that computer engineers would‚Äôve been the sexy job of the 1990s?

Hal Varian (Chief economist, Google), _The McKinsey Quarterly_, January 2009

---
## Data science is the new statistics?

> ‚ÄúI think data-scientist is a sexed up term for a statistician‚Äù

[Nate Silver](http://www.statisticsviews.com/details/feature/5133141/Nate-Silver-What-I-need-from-statisticians.html)

---
## Data science is the new statistics?

[.reduite[.center[![](./img/data-science-venn-diagram.png)]]](http://www.prooffreader.com/2016/09/battle-of-data-science-venn-diagrams.html)

---
## Le r√¥le de l'informatique

- statistique classique : les probl√®mes doivent pouvoir √™tre r√©solus de mani√®re analytique (d'o√π le succ√®s du [fr√©quentisme](https://fr.wikipedia.org/wiki/Interpr%C3%A9tations_de_la_probabilit%C3%A9#Fr%C3%A9quentisme))

- le d√©veloppement de la puissance de calcul permet de r√©soudre des probl√®mes statistiques par la simulation ([MCMC](https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo_par_cha%C3%AEnes_de_Markov))

---
## D√©veloppement de la puissance de calcul

[.reduite[.center[![](./img/moore.png)]]](http://visual.ly/infographic-about-computers)

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/altavista.png)]]](https://twitter.com/alicemazzy/status/655306196128280576?ref_src=twsrc%5Etfw)


---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/amazon.png)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/snowmobile.jpg)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

???

Jusqu'√† 100 Po par camion. 1 Po = 1000 To

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/atacama.png)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)


---
## La simulation, m√©thode reine d'estimation statistique 

Monte Carlo Markov Chain (MCMC) : papier de Metropolis et Ulam (1949)

http://chifeng.scripts.mit.edu/stuff/mcmc-demo/#HamiltonianMC,banana

---
class:inverse, center, middle

# Analyse, mod√©lisation, machine learning

---
## Que fait-on une fois qu'on a des donn√©es ?

- Exploratory Data Analysis (Tukey, 1977)
  * pas d'hypoth√®se pr√©alable √† tester, plut√¥t pour g√©n√©rer des hypoth√®ses
  * r√¥le de la datavisualisation

- test d'hypoth√®se

---
## Que fait-on une fois qu'on a des donn√©es ?

.reduite[.center[![](./img/test.png)]]

---
## Que fait-on une fois qu'on a des donn√©es ?

.reduite[.center[![](./img/Type-I-and-II-errors.jpg)]]

https://www.nutritiontactics.com/strength-training-studies-underpowered-ironic-muscle-hypertrophy-stats-explained/

---
## Que fait-on une fois qu'on a des donn√©es ?

- Exploratory Data Analysis (Tukey, 1977)
  * pas d'hypoth√®se pr√©alable √† tester, plut√¥t pour g√©n√©rer des hypoth√®ses
  * r√¥le de la datavisualisation

- test d'hypoth√®se

- **mod√®le**

---
class: center, middle, inverse

# L'√©cosyst√®me de la data science


---
## Bases de donn√©es

March√© de ~ 25 milliards USD

* g√©ants historiques: Oracle, Microsoft

* MySQL, PostgreSQL, SQLite...

* BDD orient√©es colonnes : MonetDB...

* BDD NoSQL : MongoDB, CouchDB, BigTable (Google), Neo4j, Redis...

---
## Bases de donn√©es distribu√©es : Hadoop / MapReduce

* Framework Hadoop / Cloudera, bas√© sur :
  * HDFS (Hadoop Distributed File System) pour le stockage et
  * MapReduce pour le calcul
* Alternative: Apache Spark travaille en m√©moire vive => 10 √† 100x plus rapide que Hadoop


$+$ : Permet une r√©elle scalabilit√© (ajoutons des n≈ìuds)

$-$ : Contraint fortement les algorithmes pouvant √™tre utilis√©s, qui doivent √™tre parall√©lisables
(ex : Analyse en Composantes Principales => c'est compliqu√©)

---
## Langages

- Java
- Python
- R
- Scala
- Julia
- SQL
- C / C++
- ...

---
## Logiciels d'analyse et de visualisation de donn√©es

* BI: Tableau (rachet√© par Salesforce 2019/08)

* Data science: Dataiku

* Machine Learning: Azure Machine Learning Studio de Microsoft

---
## La r√©volution par le GPU

* L'explosion du deep learning repose en partie sur l'exploitation de cartes graphiques puissantes (GPU) d√©velopp√©es √† l'origine pour les jeux vid√©o et la mod√©lisation 3D

* Nvidia, leader mondial des GPU, d√©veloppe maintenant aussi des biblioth√®ques de data science / dataviz ("Open GPU Data Science"): https://rapids.ai/
  * entre 10x et 1000x plus rapide (!) selon les algorithmes

.reduite[.center[![](./img/RAPIDS-logo-white.png)]]

---
## La r√©volution par le GPU

.reduite[.center[![](./img/rapids_arrow.png)]]


---
## Bonus: Une carte interactive 

http://xyz.insightdataengineering.com/blog/pipeline_map.html


---
class: center, middle, inverse

# Le data pipeline

---

.reduite[.center[![](./img/datapipeline.png)]]


---
## D√©finir les donn√©es dont on a besoin

.center[![](./img/define.png)]

---
## Trouver les donn√©es dont on a besoin

.center[![](./img/find.png)]

???
O√π cherchez-vous vos donn√©es ?

- d√©p√¥ts internes
- CDO
- d√©p√¥ts externes
- data brokers
- etc.

---
## Acqu√©rir les donn√©es

.center[![](./img/get.png)]

???

Connecteurs
ETL : ex Talend, Logstash


---
## V√©rifier les donn√©es

.center[![](./img/verify.png)]



???

Importance d'un sanity check

---
## V√©rifier les donn√©es

.center[[![](./img/sanity.jpg)](http://www.erogol.com/ml-work-flow-part-4-sanity-checks-data-spliting/)]



---
## Nettoyer les donn√©es

.center[![](./img/clean.png)]


???

Paradigme du *tidy data*

OpenRefine

---
## Analyser les donn√©es

.center[![](./img/analyse.png)]

---
## Communiquer les r√©sultats

.center[![](./img/present.png)]

???

dataviz
reproducible research
appli
dashboard
etc.

---

class: inverse, center, middle

# Pratique: Transparence Sant√©

---

## Transparence Sant√©

.reduite[.center[![<https://www.transparence.sante.gouv.fr/>](img/transparence-sante-home.png)]]

---

### Exploration du jeu de donn√©es

Lien direct: <https://www.transparence.sante.gouv.fr/exports-etalab/exports-etalab.zip>

* Combien d'entreprises d√©clarantes?

* Combien d'avantages, conventions, r√©mun√©rations ?

---
### Outils Unix

```sh
# nb entreprises
head -n 5 ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
wc -l ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
# nb avantages
head -n 5 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
wc -l ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# id. conventions et remunerations
```

Au 24 novembre 2018:
* entreprises: 2.812
* avantages: 9.604.936
* conventions: 4.123.166
* r√©mun√©rations: 280.981

---
## Alternative: miller

<https://github.com/johnkerl/miller>

> Miller is like awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON.  
> Miller is multi-purpose: it‚Äôs useful for data cleaning, data reduction, statistical reporting, devops, system administration, log-file processing, format conversion, and database-query post-processing.  
> Miller complements data-analysis tools such as R, pandas, etc.: you can use Miller to clean and prepare your data. While you can do basic statistics entirely in Miller, its streaming-data feature and single-pass algorithms enable you to reduce very large data sets.

<https://johnkerl.org/miller/doc/index.html>

Installation:
```sh
apt-get install miller
```

---
## Exploration avec miller
```sh
# nb entreprises
mlr --csv cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
# nb avantages
mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# id. conventions et remunerations
```

* entreprises: 2.812
* avantages: 9.604.485
* conventions: 4.120.314
* r√©mun√©rations: 280.940

---
## `wc -l != mlr cat -n` ?

* `wc -l` compte les caract√®res `\n` (attention si la derni√®re ligne d'un fichier ne se termine pas par ce caract√®re!) ;
`cat -n` compte les lignes, s√©par√©es par `\n`.

* `mlr cat -n` compte les entr√©es, champ par champ, en tenant compte des guillements doubles utilis√©s pour prot√©ger certaines valeurs textuelles.

Donc?

---
## `wc -l != mlr cat -n` !
* Certains champs de texte libre contiennent du texte incluant des `\n` (multiline strings).

```sh
grep -A1 --color=always ';"[^";]*$' ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv|less
```

---

## Exploration avec pandas
```python
import pandas as pd
df_a = pd.read_csv("~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv", sep=';')
df_a.shape
# (9604485, 36)
```

Pourquoi ne pas utiliser directement pandas?

---
## miller vs pandas: CPU

```sh
time mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# 38,53s user 1,10s system 99% cpu 39,636 total
```

```python
from time import time
t0 = time() ; df_a = pd.read_csv("~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv", sep=';') ; t1 = time() ; print(t1 - t0)
# 53.411545515060425
```

---
## miller vs pandas: RAM

```sh
/usr/bin/time -v mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# Maximum resident set size (kbytes): 2754560
# soit environ 2.6 GB
```

```python
df_a.info(memory_usage='deep')
# dtypes: int64(1), object(35)
# memory usage: 18.3 GB
```

---
## pandas: moins de RAM

Pour chaque colonne, un autre dtype est-il possible?
```python
# nb valeurs non nulles, nb uniques,
# valeur la plus fr√©quente et sa fr√©quence
df_a.describe(include='all').transpose()[['count', 'unique', 'top', 'freq']]
```
15 colonnes contiennent beaucoup d'occurrences d'un nombre restreint de valeurs distinctes.
S√©mantiquement, elles semblent correspondre √† des **variables cat√©gorielles**.

---
## pandas: dtypes

```python
cols_desc = df_a.describe(include='all').transpose()[['count', 'unique', 'top', 'freq']]
```

```python
cat_cols = cols_desc[cols_desc['unique'] < 100].index.values.tolist()
cat_dtypes = {x: 'category' for x in cat_cols}
df_a = df_a.astype(cat_dtypes, copy=False)
# verif memoire
df_a.info(memory_usage='deep')
# dtypes: category(15), int64(1), object(20)
# memory usage: 9.9 GB
```

---
## pandas: dump dtypes

`read_csv` a un argument optionnel qui permet de sp√©cifier le dtype d'une ou plusieurs colonnes.
L'inf√©rence de type est d√©sactiv√©e pour ces colonnes.

```python
# on exporte dans un json le dtype des colonnes pour
# √©viter (√† soi ou aux autres) de refaire ce travail
# pr√©liminaire
import json
col_dtypes = df_a.dtypes.astype(str).to_dict()
with open('data/avantage_dtypes.json', mode='w') as f:
    json.dump(col_dtypes, f)
```

---
## pandas: `read_csv(dtype=...)`

Nouvelle session:
```python
import pandas as pd
import json
# lecture des dtypes
with open('data/avantage_dtypes.json', mode='r') as f:
    col_dtypes = json.load(f)
df_a = pd.read_csv("declaration_avantage_2018_11_24_04_00.csv", sep=';', dtype=col_dtypes)
```

---
## pandas: et pour les autres colonnes?

```python
df_a.describe(include='object').transpose()[['count', 'unique', 'top', 'freq']]
```
* variables cat√©gorielles int√©ressantes (RAM) si unique << count
  - toutes sauf `ligne_identifiant`, `avant_convention_lie`, `benef_denomination_sociale`?

* `entreprise_identifiant` est s√ªrement une cl√© √©trang√®re (table des entreprises) ; `denomination_sociale` doit correspondre √©galement

* `benef_adresse{1..4}` sont √† interpr√©ter ensemble

```python
df_a = df_a.astype({'entreprise_identifiant': 'category', 'denomination_sociale': 'category'}, copy=False)
# [...] memory usage: 8.8 GB
# etc.
df_a['avant_date_signature'] = pd., format='%d/%m/%Y')
```

---
## pandas: dates

`avant_date_signature` doit √™tre une date, utilisons le dtype ad√©quat:
```python
df_a['avant_date_signature'] = pd.to_datetime(df_a['avant_date_signature'], format='%d/%m/%Y')
# OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 17-10-17 00:00:00
# solution: errors='coerce' ou errors='ignore'
```

```sh
mlr --csv --ifs ';' grep "17/10/0017" then cat -n ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
```

---
## Probl√®me de qualit√© 1: valeurs incorrectes

* 30 entr√©es contiennent cette date erron√©e, toutes pour des repas offerts par les laboratoires Servier √† des cardiologues de diff√©rents h√¥pitaux (le 17/10/2017?).

* Explications possibles (+/- optimistes): erreurs de saisie ind√©pendantes, erreurs de saisie li√©es (√©v√©nement? saisie group√©e?) ; les dates d√©clar√©es correctes en apparence sont-elles fiables?

* Autre exemple: `benef_ville`="MARSEILLLE"

---
## Probl√®me de qualit√© 2: valeurs de remplissage

```python
df_a["benef_identifiant_valeur"].value_counts()
```

* Les valeurs les plus fr√©quentes ressemblent √† de faux identifiants ou des valeurs de remplissage: [SO], SO (sans objet?), 0, [AUTRE], 10000000000, 00000000000, `BENEF_IDENTIFIANT_VALEUR`, [BR], NON RENSEIGNE, [0], 9999, `.`, INFORMATION NON DISPONIBLE, 10000000001, MANIPULATEUR EN RADIOLOGIE.

* V√©rification manuelle: "508331303" est un SIREN valide (ok).

---
## Bilan du jeu de donn√©es

* Volum√©trie importante: > 13 millions d'entr√©es

* Forte h√©t√©rog√©n√©it√© et faible qualit√© dues √†:
  - mode de d√©claration (peu de contr√¥les √† la soumission),
  - nombre d'entreprises d√©clarantes (> 2.800).

---
class: inverse, center, middle

# Travailler avec des donn√©es "sales"

---

## Data: the good, the bad...

.reduite[.center[![](img/tidy-9.png)]]

.reduite[.center[![](img/tidy-8.png)]]

---

## Tidy data

> "Happy families are all alike; every unhappy family is unhappy in its own way." ‚Äì‚Äì Leo Tolstoy

> "Tidy datasets are all alike, but every messy dataset is messy in its own way." ‚Äì‚Äì Hadley Wickham

.reduite[.center[![https://r4ds.had.co.nz/introduction.html](./img/data-science.png)]]

---

## Tidy data: r√©f√©rences

.reduite[.center[![](img/cover.png)]]

* Wickham, Hadley, and Garrett Grolemund. R for data science: import, tidy, transform, visualize, and model data. " O'Reilly Media, Inc.", 2016.
  - disponible gratuitement en ligne: <https://r4ds.had.co.nz/>
  - chapitre "Tidy Data": <https://r4ds.had.co.nz/tidy-data.html>

---

## Tidy data: r√©f√©rences

.reduite[.center[![](img/tidy-data.png)]]
* Hadley Wickham. Tidy data. The Journal of Statistical Software, vol. 59, 2014.
  - <http://vita.had.co.nz/papers/tidy-data.html>

---
## Data: ... and the ugly

.reduite[.center[![](img/ugly1.png)]]

---
## Data: ... and the ugly (bis)

.reduite[.center[![](img/ugly2.png)]]

---

## Rendre les donn√©es exploitables pour la dataviz

Lisa Charlotte Rost: "How to prepare your data for analysis and charting in Excel & Google Sheets"

https://blog.datawrapper.de/prepare-and-clean-up-data-for-data-visualization/

---

## OpenRefine
<http://openrefine.org>

Outil de correction semi-automatique it√©ratif:

* travail par facettes/filtres

* heuristiques de clustering: collision de cl√©s, plus proches voisins (plusieurs variantes pour chacune)

* on s√©lectionne les fusions √† r√©aliser

* plus √©ventuellement donn√©es externes (wikidata)

=> Produire rapidement une version corrig√©e d'un jeu de donn√©es (corrections simples).

---

## Conclusion
* Les probl√®mes de qualit√© sont un frein majeur √† la publication et √† la r√©utilisation de donn√©es (ouvertes).

* Ils sont issus du **travail invisibilis√© de production des donn√©es**, dont on retrouve quelques traces dans la documentation et dans les donn√©es elles-m√™mes.

* L'exploitation de jeux de donn√©es "sales" n√©cessite leur nettoyage manuel ou semi-automatique (utilisation d'outils de correction comme OpenRefine)

---
class: inverse, center, middle

# Travailler avec des donn√©es non-structur√©es

---

## Donn√©es non structur√©es

* Fichiers textes et documents (.doc, .pdf, .html, .ppt)
* Courriels
* Donn√©es issues des r√©seaux sociaux
* Images
* Fichiers sons
* Vid√©os
* Logs de serveurs, sites, applications

Comment extraire les nombreuses informations contenues dans ces donn√©es non-structur√©es?

---
## Difficult√©s

.reduite[.center[![<https://xkcd.com/1425/>](./img/tasks.png)]]

<!-- In the 60s, Marvin Minsky assigned a couple of undergrads to spend the summer programming a computer to use a camera to identify objects in a scene. He figured they'd have the problem solved by the end of the summer. Half a century later, we're still working on it. -->

---
## Branches de l'IA

* Vision par ordinateur (Computer Vision)
  - d√©tection d'objet (Object Detection)
  - reconnaissance optique de caract√®res (Optical Character Recognition)

* Traitement automatique du langage naturel (Natural Language Processing)

Progr√®s de la recherche dans ces branches de l'IA => am√©lioration des performances des syst√®mes

---
## Panama papers

* 11.4 M fichiers, 2.6 To donn√©es
* "Soit plusieurs d√©cennies de lecture jour et nuit si l‚Äôon veut aller d‚Äôun bout √† l‚Äôautre de la base de donn√©es ‚Äì sans compter la complexit√© de certains dossiers."

.reduite[.center[![<https://www.lemonde.fr/panama-papers/article/2016/04/03/panama-papers-comment-le-monde-a-travaille-sur-plus-de-11-millions-de-fichiers_4894836_4890278.html>](img/lemonde-panama.png)]]

---
## Stack technique ICIJ

* extraction du texte par OCR avec Tesseract,
* recherche de termes avec Talend,
* indexation des r√©sultats avec Apache Solr,
* tokenization, filtrage, stemming, clustering de termes avec RapidMiner,
* classification automatique de documents avec RapidMiner.

<https://www.icij.org/blog/2018/08/how-machine-learning-is-revolutionizing-journalism/>

---
## Limites

* Donn√©es:
  - Fautes d'orthographe
  - Variations de la graphie
* Masse de donn√©es √† analyser:
  - Filtrer les documents peu int√©ressants,
  - Strat√©gies de classification plus √©labor√©e,
* Syst√®mes:
  - Erreurs d'OCR
  - Erreurs de NER
  - NB: erreurs en cascade => effet multiplicatif

---
## Data pipeline

.reduite[.center[![<https://xkcd.com/2054/>](img/data_pipeline.png)]]

---
## Named Entity Recognition

Sch√©ma d'annotation des dumps Wikipedia:

* PER:	Named person or family.
* LOC:	Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains).
* ORG:	Named corporate, governmental, or other organizational entity.
* MISC:	Miscellaneous entities, e.g. events, nationalities, products or works of art.

D'autres sch√©mas d'annotation plus d√©taill√©s existent.

Vous pouvez √©laborer vos propres sch√©mas d'annotation m√©tier, d√©riv√©s ou non de sch√©mas standard, et annoter des donn√©es.

---

## Annotation de donn√©es avec Prodigy

.reduite[.center[![](./img/prodigy.png)]]

<https://prodi.gy>

---

class: inverse, center, middle

# Workshop : Introduction √† la data visualisation

[datactivist
.coop/odl_paca](https://datactivist.coop/odl_paca)

---
class: center, middle, inverse

# Mod√©liser

---
## Pourquoi mod√©liser ?

.reduite[.center[![](./img/Hibbs.jpg)]]


---
## Pourquoi mod√©liser ? Les ["deux cultures"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)

- pour analyser et expliquer

- pour pr√©dire

---
## Pourquoi mod√©liser ? Les ["deux cultures"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)

- pour analyser et expliquer (**statistiques classiques, √©conom√©trie**)

- pour pr√©dire (**machine learning, IA...**)

---
## Mod√©liser pour analyser

- un mod√®le r√©duit de la r√©alit√©

- isoler le r√¥le de chaque variable

- raisonner "toutes choses √©gales par ailleurs" (*ceteris paribus*)

---
## Mod√©liser pour analyser

Mod√©liser, c‚Äôest mettre en relation une *variable expliqu√©e*
(d√©pendante / pr√©dite) et une ou plusieurs *variables explicatives*
(ind√©pendantes / pr√©dicteurs).

$$ Y = f(X_1, X_2, X_3, ..., X_n) $$

L‚Äôestimation du mod√®le consiste √† estimer la valeur des param√®tres
(ou coefficients). Le cas du mod√®le lin√©aire :

$$ Y = Œ± + Œ≤_1X_1 + Œ≤_2X_2 + Œ≤_3X_3 + ¬∑ ¬∑ ¬∑ + Œ≤_nX_n + Œµ $$

---
## Mod√©liser pour analyser

Implique de faire des hypoth√®ses sur la sp√©cification du mod√®le :

- variables explicatives

- distribution des erreurs

---
## Les distributions

- distribution th√©orique (ex : distribution normale)

- distribution empirique

http://shiny.stat.calpoly.edu/Prob_View/

---
## All models are wrong, some are useful

> Since all models are wrong the scientist cannot obtain a "correct" one by excessive elaboration. On the contrary following William of Occam he should seek an economical description of natural phenomena. 

[George Box](https://dx.doi.org/10.1080%2F01621459.1976.10480949)

---
## All models are wrong, some are useful

.reduite[.center[![](./img/ockham.jpg)]]

---
## Estimation d'un mod√®le

Dans le cas d'un mod√®le lin√©aire => m√©thode des moindres carr√©s ordinaires (MCO/OLS)

http://setosa.io/ev/ordinary-least-squares-regression/

---
## Attention !

- Les mod√®les de r√©gression lin√©aire supposent que les relations
sont *lin√©aires* et *additives*.

- Les *r√©sidus* sont suppos√©s √™tre *normalement distribu√©s*.

- Les coefficients ne sont *pas standardis√©s* (on ne peut pas les
comparer entre eux).

- Les coefficients s‚Äôinterpr√®tent *relativement √† l‚Äôunit√© de la variable d√©pendante*.

---
## Attention !

- Les coefficients estiment l‚Äôeffet d‚Äôune variable ind√©pendante
sur la variable d√©pendante *toutes choses √©gales par ailleurs*,
c‚Äôest-√†-dire en neutralisant l‚Äôeffet des autres variables.

- La qualit√© globale du mod√®le peut √™tre quantifi√© au travers du
$R^2$, qui repr√©sente la part de variance (de la variable
d√©pendante) expliqu√©e.

- Pour les variables ind√©pendantes cat√©goriques, on estime un
coefficient par modalit√©, √† l‚Äôexception de la premi√®re
(baseline).

---
## Mod√®les statistiques

Compromis entre intelligibilit√© et fid√©lit√© aux donn√©es

---
## Underfitting et overfitting

.reduite[.center[![](./img/underfit.png)]]

---
## Underfitting et overfitting

- diff√©rencier donn√©es d'apprentissage et donn√©es de test 

- n'utiliser les donn√©es de confirmation (test) qu'une fois 

---
## Extrapolation

[.reduite[.center[![](./img/sinus.png)]]](http://r4ds.had.co.nz/model-basics.html)

---
## Et le machine learning alors ?

- Fondamentalement, mod√©lisation et machine learning ne sont pas diff√©rents, du point de vue d'un statisticien : mod√©liser un $Y$ en fonction d'un vecteur de $X_i$

- une des diff√©rences principales toutefois : veut-on pr√©voir ou comprendre/analyser ?

- et donc : peut-on, veut-on interpr√©ter les coefficients ?

- en pratique : machine learning porte g√©n√©ralement sur des donn√©es plus complexes que la mod√©lisation traditionnelle

- souvent beaucoup de valeurs manquantes 

---
## Et le machine learning alors ?

.reduite[.center[![](./img/ratings.png)]]

---
## Concepts de machine learning

- Apprentissage supervis√© vs non supervis√© 

- Apprentissage supervis√© : il faut des donn√©es d√©j√† class√©es/√©talonn√©es. Souvent √† la main ! => *#digitallabour*

---
## Apprentissage supervis√© 

[.reduite[.center[![](./img/captcha.jpg)]]](https://fakecaptcha.com)

---
## Apprentissage supervis√©

[.reduite[.center[![](./img/opensolarmap.png)]]](https://cquest.hackpad.com/OpenSolarMap-9oMiYswLksF)

---
## Apprentissage supervis√©

[.reduite[.center[![](./img/inbox.png)]]](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf)

---
## Apprentissage non supervis√© 


- probl√®me majeur : r√©duction de la dimensionnalit√©

- jeux de donn√©es √† tr√®s haute dimensionnalit√© : impossible √† explorer visuellement. Comment simplifier l'information et la r√©sumer ?

.reduite[.center[![](./img/house.png)]]

---
## Apprentissage non supervis√© 

https://gallery.shinyapps.io/LDAelife/

---
class: inverse, center, middle

# Merci !

#<mathieu@datactivist.coop>

# √âvaluation de  la formation
