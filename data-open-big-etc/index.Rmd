---
title: "Data"
subtitle: "Open, Big, etc"
author: "Mathieu Morey"
date: "2020-09-14"
output:
  SlidesDatactivist::moon_reader:
    seal: false
    css: [default, datactivist, datactivist-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
params:
  event: "MScT CSE - CSDS"
  slug: data-open-big-etc/
---

class: center, middle
<!-- background-image: url(./img/seurat.jpg) -->
background-size: cover
background-position: 50% 50%

# Data
## Open, Big, etc
<BR><BR><BR>
## Mathieu Morey (Datactivist)

### 2020-09-14
---

class: center, middle

These slides online : `r paste0("http://moreymat.github.io/", params$slug)`

Sources : `r paste0("https://github.com/moreymat/ecm-cse-csds/", params$slug)`

Adapted from original content by Samuel Go√´ta and Jo√´l Gombin (Datactivist).
Productions by Datactivist are freely reusable under the terms of the [Creative Commons 4.0 BY-SA](https://creativecommons.org/licenses/by-sa/4.0/legalcode.fr) license.

<BR>
<BR>

![](https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-sa.png)


---
## Datactivist : Who we are

<BR><BR><BR><BR>

[![](https://github.com/datactivist/slides_datactivist/raw/master/inst/rmarkdown/templates/xaringan/resources/img/logo.png)](https://datactivist.coop)

### We .red[open data], we make them .red[useful]

---
## Datactivist : Who we are


![](https://datactivist.coop/images/photo-equipe.jpg)

---
## Datactivist : Who we are

- Datactivist is a .red[**pure player in open data**] launched in 2016, by Samuel Go√´ta et Jo√´l Gombin.

<!-- TODO translate  -->
- Se positionnant sur .red[**toutes les √©tapes du travail d‚Äôouverture des donn√©es**], Datactivist travaille tant avec les producteurs de donn√©es qu‚Äôavec les r√©utilisateurs et participe √† l‚Äôappropriation des donn√©es par chacun.

- Nous appliquons nos propres .red[**valeurs**] : nous sommes une coop√©rative ; nos supports de formation et nos contenus sont librement r√©utilisables, publi√©s en licence Creative Commons.

- Une approche issue de la recherche : voir notamment **https://datactivist.coop/these**. 

- Nous animons la communaut√© [#TeamOpenData](https://teamopendata.org).

---
## Nos activit√©s

- Conseil sur les .red[**strat√©gies d‚Äôouverture de donn√©es**] : nous aidons les organisations dans la conception et la mise en ≈ìuvre de leur strat√©gie d‚Äôouverture de donn√©es.


- .red[**Accompagnement dans la r√©utilisation de donn√©es ouvertes**] : nous aidons les organisations √† utiliser les donn√©es au quotidien. 

- .red[**Sensibilisation et formation √† la donn√©e**] : nous formons √† la culture g√©n√©rale des donn√©es, nous enseignons les grands principes et bonnes pratiques de l'open data et nous introduisons √† la data science. 

- .red[**M√©diation de donn√©es**] : nous organisons des hackathons, des open data camps, des exp√©ditions de donn√©es...

???

La m√©diation de donn√©es est aussi fondamentalement une animation de communaut√©(s). 

---
class:middle, center
## Warm up : 5 minutes, 20 data points

You have 5 minutes.

You must find 20 data points in your immediate surroundings.

(You cannot use any electronic device)

.footnote[[source](http://infolabs.io/5-minutes-20-donnees)]

---
class:center,inverse, middle
# What is a data point ?
---
class:center,inverse, middle
# According to you... ?
---
# The Roman censor, ancestor of statistics
.reduite3[![](img/asterix.png)]

.footnote[Source : *Asterix chez les pictes*, ¬© Albert Ren√© 2013]
---
# The Roman censor, ancestor of statistics
.reduite3[![](img/asterix1.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]
---
## Statistics : tool for government and proof
.pull-left[.middle[Statistics is simultaneously :

  + **mean of government** (_Statistik_ - 18th century), et
  
  + **tool of proof** (_statistics_ - 19e si√®cle)]]
.pull-right[![center](./img/desrosieres1.jpg)]
---
  
## [Quantifier, c'est convenir puis mesurer](https://www.pressesdesmines.com/wp-content/uploads/2011/01/PourSocioHistExtr.pdf)

.pull-left[
> Le verbe quantifier est employ√© ici dans un sens large : **exprimer et
faire exister sous une forme num√©rique ce qui, auparavant, √©tait exprim√© par
des mots et non par des nombres**.
]

.pull-right[![ ](img/desrosi.jpeg)]

---
## [Quantifier, c'est convenir puis mesurer](https://www.pressesdesmines.com/wp-content/uploads/2011/01/PourSocioHistExtr.pdf)

.middle.reduite3[![](img/asterix2.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]

---
## Quantifier, c'est inscrire et figer une r√©alit√© sans cesse mouvante
.reduite2[![](img/asterix3.png)]

.footnote[*Asterix chez les pictes*, ¬© Albert Ren√© 2013]

---
## Etymologie

### Latin : _dare_ (donner) > _datum_ (donn√©) > _data_ (donn√©s)
<br/><br/>
Ce qui est √©vident, va de soi, est accept√© sans discussion

<br/><br/>

> From its first vernacular formulation, the existence of a datum has been independent of any
consideration of corresponding ontological truth. When a fact is proven false, it ceases
to be a fact. False data is data nonetheless.

.footnote[[Rosenberg, 2013](https://mitpress.mit.edu/books/raw-data-oxymoron)]

---
## Usage de "data"

Le sens moderne appara√Æt √† la fin du 18e si√®cle. 

Renvoie √† des exp√©riences, des collectes d'√©l√©ments.

.reduite[![](img/data.png)]

---
## ‚ÄúDatafication‚Äù : la mise en donn√©es du monde
> ‚ÄúL'immense gisement de donn√©es num√©riques d√©coule de la capacit√© √† param√©trer des aspects du monde et de la vie humaine qui n'avaient encore jamais √©t√© quantifi√©s. On peut qualifier ce processus de **¬´ mise en donn√©es ¬ª (datafication)**. 

> [‚Ä¶] ‚ÄúLa mise en donn√©es d√©signe autre chose que la num√©risation, laquelle consiste √† traduire un contenu analogique - texte, film, photographie - en une s√©quence de 1 et de 0 lisible par un ordinateur. Elle se r√©f√®re √† une action bien plus vaste, et aux implications encore insoup√ßonn√©es : **num√©riser non plus des documents, mais tous les aspects de la vie**.‚Äù

.footnote[[Kenneth Cukier, ‚ÄúMise en donn√©es du monde, le d√©luge num√©rique‚Äù](https://www.monde-diplomatique.fr/2013/07/CUKIER/49318)]
---

## La "nombrification" du monde
.pull-left[![](https://cefres.hypotheses.org/files/2017/06/couv_REY.jpg)]
.pull-right[
> La num√©risation ne serait pas survenue sans une "nombrification" pr√©alable qui consiste √† quantifier de plus en plus d'aspects de notre exp√©rience du r√©el.


> **Au commencement √©tait le verbe, il semble √† la fin que tout devient nombre.**


> Personne ne saurait parler s√©rieusement de l'√©tat de la soci√©t√© et discuter politique sans se r√©f√©rer aux informations quantitatives. ]

---
## Le nouveau positivisme des donn√©es

> *If you asked me to describe the rising philosophy of the day, I‚Äôd say it is **data-ism**. 
We now have the ability to gather huge amounts of data. 
This ability seems to carry with it certain cultural assumptions ‚Äî that everything that can be measured should be measured; that data is a transparent and reliable lens that allows us to filter out emotionalism and ideology; that data will help us do remarkable things ‚Äî like foretell the future.*


Jeff Brookes, √©ditorialiste du New York Times

---
## Aux sources de la mise en donn√©es du monde

.pull-left[
- Rencontre, dans la Californie des ann√©es 1960, entre la Nouvelle Gauche et les Nouveaux Communalistes sur fond de LSD et de recherche militaire

- L'inspiration de la cybern√©tique (N. Wiener) : objets techniques et √™tres humains constituent un m√™me syst√®me sociotechhnique, r√©gul√© par l'information

- Exemple de Steward Brand, fondateur du _Whole Earth Catalog_ puis de Wired => ["Forest Gump de l'Internet"](https://questionsdecommunication.revues.org/8619)]
.pull-right[![](./img/wholeearthcatalog.jpg)]

---
## "Raw data" is an oxymoron

.pull-left[
> Data are always already ‚Äúcooked‚Äù and never entirely ‚Äúraw.‚Äù

> Data need to be imagined _as_ data to exist and function as such, and the imagination of data entails an interpretive base.

]
.pull-right[![](https://mitpress.mit.edu/sites/default/files/styles/large_book_cover/http/mitp-content-server.mit.edu%3A18180/books/covers/cover/%3Fcollid%3Dbooks_covers_0%26isbn%3D9780262518284%26type%3D.jpg?itok=PQI0SkzN)]
.footnote[[Source](https://mitpress.mit.edu/books/raw-data-oxymoron)]

---
class:inverse, middle, center
# Vers une d√©finition des donn√©es
---

## La pyramide Data-Information-Knowledge-Wisdom

.pull-left[[![largeur](./img/DIKW_Pyramid.svg)](https://commons.wikimedia.org/w/index.php?curid=37705247)]

.pull-right[Attribu√©e √† [Russell Ackoff](http://en.wikipedia.org/wiki/Russell_L._Ackoff), 1989

Les donn√©es peuvent √™tre des :

- faits
- signaux/stimuli
- symboles]

---
## Vers une d√©finition des donn√©es

.pull-left.reduite2[![](img/kitchin.jpg)]
.pull-right[
> *Data are commonly understood to be the raw material produced by **abstracting the world** into categories, measures and other representational forms ‚Äì numbers, characters, symbols, images, sounds, electromagnetic waves, bits ‚Äì that constitute the **building blocks** from which information and knowledge are created.*

‚è∫ enregistrabilit√©

üèó> briques de base ("*buildings blocks*")
]

---
class:middle
## Data or capta ?

> *Technically, then, what we understand as data are actually **capta** (derived from the Latin capere, meaning ‚Äòto take‚Äô); those units of data that have been selected and harvested from the sum of all potential data.*

[Kitchin, 2014](https://books.google.fr/books?hl=fr&lr=&id=GfOICwAAQBAJ&oi=fnd&pg=PP1&dq=kitchin+data+revolution&ots=pcyfMTZh-V&sig=dQyPTL3AIN_4RdWvtBFw4VjdAa4#v=onepage&q=kitchin%20data%20revolution&f=false)

---
class:middle
## Donn√©es ou obtenues ? 


> ¬´ D√©cid√©ment, on ne devrait jamais parler de ‚Äúdonn√©es‚Äù, mais toujours d‚Äô ‚Äúobtenues‚Äù. ¬ª 

Bruno Latour, 1993

---

class:center, middle, inverse
## Donn√©es, donn√©es... quelles donn√©es ?

---
## Donn√©es statistiques

.pull-left[
Diff√©rents types de variables : 

- quantitative: notion de grandeur
  * discr√®te vs continue

- qualitative: notion de cat√©gories
  * nominale : cat√©gories nomm√©es (mari√© / c√©libataire / divorc√© / veuf)
  * ordinale : cat√©gories nomm√©es et ordonn√©es entre elles (faible / moyen / fort)
  * d'intervalles : cat√©gories ordonn√©es dont les valeurs successives sont s√©par√©es par des intervalles identiques (12-16¬∞C / 16-20¬∞C / 20-24 ¬∞C ‚Ä¶)

]
.pull-right[![](img/spread.png)]

---
## Donn√©es au sens large
.pull-left[
Non num√©riques (directement): texte, image, vid√©o, son...

  + peuvent √™tre converties en donn√©es quantitatives

  + risque de perdre la richesse des donn√©es originales
  
  + analyse qualitative de donn√©es
  
]
.pull-right[![](img/text_mining_intro_2.png)]

---
## Exemple : les annotations en text mining

.reduite[![](img/annotation.png)]

---
## Donn√©es structur√©es

.pull-left[
Des donn√©es dot√©es d'un mod√®le qui d√©finit les relations entre les composantes de la base de donn√©es

  + Ex : base de donn√©es relationnelle SQL
  
  + Lisibles machine
  
  + Faciles √† analyser, manipuler, visualiser...
]
.pull-right[![](img/sql.jpeg)]

---
## Donn√©es semi-structur√©es
.pull-left[
Pas de mod√®le pr√©d√©fini : structure irr√©guli√®re, implicite... mais donn√©es organis√©es n√©anmoins, ensemble raisonnable de champs

Exemple : XML, JSON

Possible de trier, ordonner et structurer les donn√©es
]
.pull-right[![](img/OCDSjson.jpg)]

---
## Donn√©es non structur√©es

.pull-left[
* Pas de structure commune identifiable
* Exemple : BDD NoSQL, logs
* G√©n√©ralement qualitatives
* Difficilement combin√©es ou analys√©es quantitativement

Les donn√©es non structur√©es croitraient 15x plus que les donn√©es structur√©es
 
Machine learning de + en + capable d'analyser ces donn√©es.]
.pull-right[![](img/structured-vs-unstructured-data.png)]

---
## Donn√©es captur√©es, √©chapp√©es, transitoires 

** Donn√©es captur√©es**

Observation, enqu√™te, exp√©rimentation, prise de notes, capteurs... => intention de g√©n√©rer des donn√©es

** Donn√©es √©chapp√©es**

Sous-produit d'un moteur ou d'un syst√®me dont la fonction premi√®re est autre

** Donn√©es transitoires**

Echapp√©es qui ne sont jamais examin√©es, transform√©es ou analys√©es


---
## Donn√©es d√©riv√©es

R√©sultat d'un traitement ou une analyse suppl√©mentaire de donn√©es captur√©es. 

Exemple avec les [donn√©es de Google Maps](https://www.justinobeirne.com/google-maps-moat) : 


![](https://static1.squarespace.com/static/54ff63f0e4b0bafce6932642/t/5a383fdb41920241ebce859d/1513635810327/3-1+-+Making+AOIs.gif?format=1500w)

---
## Donn√©es d√©riv√©es

.reduite2[![](./img/nasa.jpg)]
---
## Index, attributs, m√©tadonn√©es

**Index**

Des donn√©es permettent l'identification et la mise en relation. Essentiels pour enrichir les donn√©es

**Attributs**

Des donn√©es repr√©sentent les aspects d'un ph√©nom√®ne, mais ne sont pas des index (pas identifiants uniques)

**M√©tadonn√©es**

Des donn√©es sur les donn√©es. Peuvent √™tre descriptives, structurelles ou administratives. Standard : Dublin Core. 

---
## Les donn√©es crowdsourc√©es
.pull-left[Des donn√©es produites par des citoyens, des communs partag√©s et gouvern√©s par leurs producteurs

Exemple : [OpenStreetMap](https://www.openstreetmap.org/query?lat=43.52367&lon=5.43256), le wiki de la carte]
.pull-right[.reduite[![](img/osm.png)]]

---
class:inverse, middle, center
# De l'open data au big data

---
## Big data
![](http://www.usine-digitale.fr/mediatheque/0/3/5/000351530/big-data.jpg)


---
## L'obsession du volume de donn√©es

.pull-left[
**Quelques chiffres omnipr√©sents** : 
- le volume de donn√©es produit double tous les 3 ans (Gantz & Reisel 2011)
- 90% des donn√©es cr√©√©es dans les deux derni√®res ann√©es (IBM 2012)
- 40% : croissance annuelle de la production de donn√©es (Maniyka et al. 2011)
]
.pull-right[![](img/whybig.png)]

---
## L'obsession du volume de donn√©es

**Probl√®mes de cette approche** : 
- Estimations guid√©es par des int√©r√™ts commerciaux
- Ne d√©finit pas ce que sont ces donn√©es
- R√©sume le big data au Volume
- Explique mal la mise en donn√©es du monde

---
## Les promesses du big data

Kitchin (2014) r√©sume les promesses du big data : 
- **‚ÄúGoverning people‚Äù** : dans la continuit√© de la statistique, am√©liorer la connaissance de l‚Äôadministration et pr√©dire les crimes

- **‚ÄúManaging organisations‚Äù** : am√©liorer le fonctionnement de toutes les composantes de l‚Äôorganisation par l‚Äôexploitation des donn√©es

- **‚ÄúLeveraging value and producing capital‚Äù** : micro-ciblage marketing, optimisation des magasins et des op√©rations, efficience de la chaine

- **‚ÄúCreating Better places‚Äù** : gouverner les villes avec des donn√©es (smart city) 

- **Un nouveau paradigme scientifique** : une nouvelle √®re guid√©e par les corr√©lations

---
## Linked data
.pull-left[
* pouss√© par W3C et Tim Berners-Lee
* Web s√©mantique / web des donn√©es
* RDF / SPARQL
* wikidata => http://projetjourdain.org/network/index.html
]
.pull-right[![](http://linkeddata.org/static/images/lod-datasets_2009-07-14_cropped.png)]

---
[![](img/histro.png)](http://histropedia.com/timeline/3jrttpg9bg0t/Google)

---
## API
.pull-left[
- Application Programming Interface => un programme vu de la surface

- les machines parlent aux machines

- donn√©e dynamique => ouverture potentiellement limit√©e et contr√¥l√©e 

- un exemple : [overpass turbo](https://overpass-turbo.eu/)]
.pull-right[![](https://d1avok0lzls2w.cloudfront.net/img_uploads/apis-for-marketers.png)]

---
class: middle, center

# Partie 2 : 
# ouvrir la boite noire de la data science

---
class:middle
## Programme

- Qu'est-ce que la data science ?
- Le data pipeline : acqu√©rir les donn√©es, les v√©rifier, les nettoyer, les analyser, les pr√©senter

---
class:middle
## Bonus

- Data visualisation : quel format et quel outil choisir pour quelle fonction ?
- Mod√©liser pour pr√©dire : introduction au machine learning et deep learning

---
class: middle, center, inverse

# Qu'est-ce que la data science ?

---
## Au commencement √©tait la statistique

- une vieille science (18e si√®cle), pour aider les √âtats (_Statistik_) mais aussi des entreprises priv√©es (au d√©part, les assureurs => actuariat)

- fond√©e sur les probabilit√©s

- faite par des math√©maticiens

- forte dimension th√©orique

---
## Au commencement √©tait la statistique

<iframe src="http://giphy.com/embed/9ADoZQgs0tyww" width="100%" height="450" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="http://giphy.com/gifs/obama-awesome-statistics-9ADoZQgs0tyww">via GIPHY</a></p>

---
## Au commencement √©tait la statistique

> I keep saying the sexy job in the next ten years will be statisticians. People think I‚Äôm joking, but who would‚Äôve guessed that computer engineers would‚Äôve been the sexy job of the 1990s?

Hal Varian (Chief economist, Google), _The McKinsey Quarterly_, January 2009

---
## Data science is the new statistics?

> ‚ÄúI think data-scientist is a sexed up term for a statistician‚Äù

[Nate Silver](http://www.statisticsviews.com/details/feature/5133141/Nate-Silver-What-I-need-from-statisticians.html)

---
## Data science is the new statistics?

[.reduite[.center[![](./img/data-science-venn-diagram.png)]]](http://www.prooffreader.com/2016/09/battle-of-data-science-venn-diagrams.html)

---
## Le r√¥le de l'informatique

- statistique classique : les probl√®mes doivent pouvoir √™tre r√©solus de mani√®re analytique (d'o√π le succ√®s du [fr√©quentisme](https://fr.wikipedia.org/wiki/Interpr%C3%A9tations_de_la_probabilit%C3%A9#Fr%C3%A9quentisme))

- le d√©veloppement de la puissance de calcul permet de r√©soudre des probl√®mes statistiques par la simulation ([MCMC](https://fr.wikipedia.org/wiki/M%C3%A9thode_de_Monte-Carlo_par_cha%C3%AEnes_de_Markov))

---
## D√©veloppement de la puissance de calcul

[.reduite[.center[![](./img/moore.png)]]](http://visual.ly/infographic-about-computers)

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/altavista.png)]]](https://twitter.com/alicemazzy/status/655306196128280576?ref_src=twsrc%5Etfw)


---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/amazon.png)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/snowmobile.jpg)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)

???

Jusqu'√† 100 Po par camion. 1 Po = 1000 To

---
## D√©veloppement de la capacit√© de stockage

[.reduite[.center[![](./img/atacama.png)]]](https://aws.amazon.com/blogs/aws/aws-snowmobile-move-exabytes-of-data-to-the-cloud-in-weeks/)


---
## La simulation, m√©thode reine d'estimation statistique 

Monte Carlo Markov Chain (MCMC) : papier de Metropolis et Ulam (1949)

http://chifeng.scripts.mit.edu/stuff/mcmc-demo/#HamiltonianMC,banana

---
class:inverse, center, middle

# Analyse, mod√©lisation, machine learning

---
## Que fait-on une fois qu'on a des donn√©es ?

- Exploratory Data Analysis (Tukey, 1977)
  * pas d'hypoth√®se pr√©alable √† tester, plut√¥t pour g√©n√©rer des hypoth√®ses
  * r√¥le de la datavisualisation

- test d'hypoth√®se

---
## Que fait-on une fois qu'on a des donn√©es ?

.reduite[.center[![](./img/test.png)]]

---
## Que fait-on une fois qu'on a des donn√©es ?

.reduite[.center[![](./img/Type-I-and-II-errors.jpg)]]

https://www.nutritiontactics.com/strength-training-studies-underpowered-ironic-muscle-hypertrophy-stats-explained/

---
## Que fait-on une fois qu'on a des donn√©es ?

- Exploratory Data Analysis (Tukey, 1977)
  * pas d'hypoth√®se pr√©alable √† tester, plut√¥t pour g√©n√©rer des hypoth√®ses
  * r√¥le de la datavisualisation

- test d'hypoth√®se

- **mod√®le**

---
class: center, middle, inverse

# L'√©cosyst√®me de la data science


---
## Bases de donn√©es

March√© de ~ 25 milliards USD

* g√©ants historiques: Oracle, Microsoft

* MySQL, PostgreSQL, SQLite...

* BDD orient√©es colonnes : MonetDB...

* BDD NoSQL : MongoDB, CouchDB, BigTable (Google), Neo4j, Redis...

---
## Bases de donn√©es distribu√©es : Hadoop / MapReduce

* Framework Hadoop / Cloudera, bas√© sur :
  * HDFS (Hadoop Distributed File System) pour le stockage et
  * MapReduce pour le calcul
* Alternative: Apache Spark travaille en m√©moire vive => 10 √† 100x plus rapide que Hadoop


$+$ : Permet une r√©elle scalabilit√© (ajoutons des n≈ìuds)

$-$ : Contraint fortement les algorithmes pouvant √™tre utilis√©s, qui doivent √™tre parall√©lisables
(ex : Analyse en Composantes Principales => c'est compliqu√©)

---
## Langages

- Java
- Python
- R
- Scala
- Julia
- SQL
- C / C++
- ...

---
## Logiciels d'analyse et de visualisation de donn√©es

* BI: Tableau (rachet√© par Salesforce 2019/08)

* Data science: Dataiku

* Machine Learning: Azure Machine Learning Studio de Microsoft

---
## La r√©volution par le GPU

* L'explosion du deep learning repose en partie sur l'exploitation de cartes graphiques puissantes (GPU) d√©velopp√©es √† l'origine pour les jeux vid√©o et la mod√©lisation 3D

* Nvidia, leader mondial des GPU, d√©veloppe maintenant aussi des biblioth√®ques de data science / dataviz ("Open GPU Data Science"): https://rapids.ai/
  * entre 10x et 1000x plus rapide (!) selon les algorithmes

.reduite[.center[![](./img/RAPIDS-logo-white.png)]]

---
## La r√©volution par le GPU

.reduite[.center[![](./img/rapids_arrow.png)]]


---
## Bonus: Une carte interactive 

http://xyz.insightdataengineering.com/blog/pipeline_map.html


---
class: center, middle, inverse

# Le data pipeline

---

.reduite[.center[![](./img/datapipeline.png)]]


---
## D√©finir les donn√©es dont on a besoin

.center[![](./img/define.png)]

---
## Trouver les donn√©es dont on a besoin

.center[![](./img/find.png)]

???
O√π cherchez-vous vos donn√©es ?

- d√©p√¥ts internes
- CDO
- d√©p√¥ts externes
- data brokers
- etc.

---
## Acqu√©rir les donn√©es

.center[![](./img/get.png)]

???

Connecteurs
ETL : ex Talend, Logstash


---
## V√©rifier les donn√©es

.center[![](./img/verify.png)]



???

Importance d'un sanity check

---
## V√©rifier les donn√©es

.center[[![](./img/sanity.jpg)](http://www.erogol.com/ml-work-flow-part-4-sanity-checks-data-spliting/)]



---
## Nettoyer les donn√©es

.center[![](./img/clean.png)]


???

Paradigme du *tidy data*

OpenRefine

---
## Analyser les donn√©es

.center[![](./img/analyse.png)]

---
## Communiquer les r√©sultats

.center[![](./img/present.png)]

???

dataviz
reproducible research
appli
dashboard
etc.

---

class: inverse, center, middle

# Pratique: Transparence Sant√©

---

## Transparence Sant√©

.reduite[.center[![<https://www.transparence.sante.gouv.fr/>](img/transparence-sante-home.png)]]

---

### Exploration du jeu de donn√©es

Lien direct: <https://www.transparence.sante.gouv.fr/exports-etalab/exports-etalab.zip>

* Combien d'entreprises d√©clarantes?

* Combien d'avantages, conventions, r√©mun√©rations ?

---
### Outils Unix

```sh
# nb entreprises
head -n 5 ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
wc -l ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
# nb avantages
head -n 5 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
wc -l ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# id. conventions et remunerations
```

Au 24 novembre 2018:
* entreprises: 2.812
* avantages: 9.604.936
* conventions: 4.123.166
* r√©mun√©rations: 280.981

---
## Alternative: miller

<https://github.com/johnkerl/miller>

> Miller is like awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON.  
> Miller is multi-purpose: it‚Äôs useful for data cleaning, data reduction, statistical reporting, devops, system administration, log-file processing, format conversion, and database-query post-processing.  
> Miller complements data-analysis tools such as R, pandas, etc.: you can use Miller to clean and prepare your data. While you can do basic statistics entirely in Miller, its streaming-data feature and single-pass algorithms enable you to reduce very large data sets.

<https://johnkerl.org/miller/doc/index.html>

Installation:
```sh
apt-get install miller
```

---
## Exploration avec miller
```sh
# nb entreprises
mlr --csv cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/entreprise_2018_11_24_04_00.csv
# nb avantages
mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# id. conventions et remunerations
```

* entreprises: 2.812
* avantages: 9.604.485
* conventions: 4.120.314
* r√©mun√©rations: 280.940

---
## `wc -l != mlr cat -n` ?

* `wc -l` compte les caract√®res `\n` (attention si la derni√®re ligne d'un fichier ne se termine pas par ce caract√®re!) ;
`cat -n` compte les lignes, s√©par√©es par `\n`.

* `mlr cat -n` compte les entr√©es, champ par champ, en tenant compte des guillements doubles utilis√©s pour prot√©ger certaines valeurs textuelles.

Donc?

---
## `wc -l != mlr cat -n` !
* Certains champs de texte libre contiennent du texte incluant des `\n` (multiline strings).

```sh
grep -A1 --color=always ';"[^";]*$' ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv|less
```

---

## Exploration avec pandas
```python
import pandas as pd
df_a = pd.read_csv("~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv", sep=';')
df_a.shape
# (9604485, 36)
```

Pourquoi ne pas utiliser directement pandas?

---
## miller vs pandas: CPU

```sh
time mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# 38,53s user 1,10s system 99% cpu 39,636 total
```

```python
from time import time
t0 = time() ; df_a = pd.read_csv("~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv", sep=';') ; t1 = time() ; print(t1 - t0)
# 53.411545515060425
```

---
## miller vs pandas: RAM

```sh
/usr/bin/time -v mlr --csv --ifs ';' cat -n then tail -n 1 ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
# Maximum resident set size (kbytes): 2754560
# soit environ 2.6 GB
```

```python
df_a.info(memory_usage='deep')
# dtypes: int64(1), object(35)
# memory usage: 18.3 GB
```

---
## pandas: moins de RAM

Pour chaque colonne, un autre dtype est-il possible?
```python
# nb valeurs non nulles, nb uniques,
# valeur la plus fr√©quente et sa fr√©quence
df_a.describe(include='all').transpose()[['count', 'unique', 'top', 'freq']]
```
15 colonnes contiennent beaucoup d'occurrences d'un nombre restreint de valeurs distinctes.
S√©mantiquement, elles semblent correspondre √† des **variables cat√©gorielles**.

---
## pandas: dtypes

```python
cols_desc = df_a.describe(include='all').transpose()[['count', 'unique', 'top', 'freq']]
```

```python
cat_cols = cols_desc[cols_desc['unique'] < 100].index.values.tolist()
cat_dtypes = {x: 'category' for x in cat_cols}
df_a = df_a.astype(cat_dtypes, copy=False)
# verif memoire
df_a.info(memory_usage='deep')
# dtypes: category(15), int64(1), object(20)
# memory usage: 9.9 GB
```

---
## pandas: dump dtypes

`read_csv` a un argument optionnel qui permet de sp√©cifier le dtype d'une ou plusieurs colonnes.
L'inf√©rence de type est d√©sactiv√©e pour ces colonnes.

```python
# on exporte dans un json le dtype des colonnes pour
# √©viter (√† soi ou aux autres) de refaire ce travail
# pr√©liminaire
import json
col_dtypes = df_a.dtypes.astype(str).to_dict()
with open('data/avantage_dtypes.json', mode='w') as f:
    json.dump(col_dtypes, f)
```

---
## pandas: `read_csv(dtype=...)`

Nouvelle session:
```python
import pandas as pd
import json
# lecture des dtypes
with open('data/avantage_dtypes.json', mode='r') as f:
    col_dtypes = json.load(f)
df_a = pd.read_csv("declaration_avantage_2018_11_24_04_00.csv", sep=';', dtype=col_dtypes)
```

---
## pandas: et pour les autres colonnes?

```python
df_a.describe(include='object').transpose()[['count', 'unique', 'top', 'freq']]
```
* variables cat√©gorielles int√©ressantes (RAM) si unique << count
  - toutes sauf `ligne_identifiant`, `avant_convention_lie`, `benef_denomination_sociale`?

* `entreprise_identifiant` est s√ªrement une cl√© √©trang√®re (table des entreprises) ; `denomination_sociale` doit correspondre √©galement

* `benef_adresse{1..4}` sont √† interpr√©ter ensemble

```python
df_a = df_a.astype({'entreprise_identifiant': 'category', 'denomination_sociale': 'category'}, copy=False)
# [...] memory usage: 8.8 GB
# etc.
df_a['avant_date_signature'] = pd., format='%d/%m/%Y')
```

---
## pandas: dates

`avant_date_signature` doit √™tre une date, utilisons le dtype ad√©quat:
```python
df_a['avant_date_signature'] = pd.to_datetime(df_a['avant_date_signature'], format='%d/%m/%Y')
# OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 17-10-17 00:00:00
# solution: errors='coerce' ou errors='ignore'
```

```sh
mlr --csv --ifs ';' grep "17/10/0017" then cat -n ~/datasets/transparence-sante/2018-11-24/declaration_avantage_2018_11_24_04_00.csv
```

---
## Probl√®me de qualit√© 1: valeurs incorrectes

* 30 entr√©es contiennent cette date erron√©e, toutes pour des repas offerts par les laboratoires Servier √† des cardiologues de diff√©rents h√¥pitaux (le 17/10/2017?).

* Explications possibles (+/- optimistes): erreurs de saisie ind√©pendantes, erreurs de saisie li√©es (√©v√©nement? saisie group√©e?) ; les dates d√©clar√©es correctes en apparence sont-elles fiables?

* Autre exemple: `benef_ville`="MARSEILLLE"

---
## Probl√®me de qualit√© 2: valeurs de remplissage

```python
df_a["benef_identifiant_valeur"].value_counts()
```

* Les valeurs les plus fr√©quentes ressemblent √† de faux identifiants ou des valeurs de remplissage: [SO], SO (sans objet?), 0, [AUTRE], 10000000000, 00000000000, `BENEF_IDENTIFIANT_VALEUR`, [BR], NON RENSEIGNE, [0], 9999, `.`, INFORMATION NON DISPONIBLE, 10000000001, MANIPULATEUR EN RADIOLOGIE.

* V√©rification manuelle: "508331303" est un SIREN valide (ok).

---
## Bilan du jeu de donn√©es

* Volum√©trie importante: > 13 millions d'entr√©es

* Forte h√©t√©rog√©n√©it√© et faible qualit√© dues √†:
  - mode de d√©claration (peu de contr√¥les √† la soumission),
  - nombre d'entreprises d√©clarantes (> 2.800).

---
class: inverse, center, middle

# Travailler avec des donn√©es "sales"

---

## Data: the good, the bad...

.reduite[.center[![](img/tidy-9.png)]]

.reduite[.center[![](img/tidy-8.png)]]

---

## Tidy data

> "Happy families are all alike; every unhappy family is unhappy in its own way." ‚Äì‚Äì Leo Tolstoy

> "Tidy datasets are all alike, but every messy dataset is messy in its own way." ‚Äì‚Äì Hadley Wickham

.reduite[.center[![https://r4ds.had.co.nz/introduction.html](./img/data-science.png)]]

---

## Tidy data: r√©f√©rences

.reduite[.center[![](img/cover.png)]]

* Wickham, Hadley, and Garrett Grolemund. R for data science: import, tidy, transform, visualize, and model data. " O'Reilly Media, Inc.", 2016.
  - disponible gratuitement en ligne: <https://r4ds.had.co.nz/>
  - chapitre "Tidy Data": <https://r4ds.had.co.nz/tidy-data.html>

---

## Tidy data: r√©f√©rences

.reduite[.center[![](img/tidy-data.png)]]
* Hadley Wickham. Tidy data. The Journal of Statistical Software, vol. 59, 2014.
  - <http://vita.had.co.nz/papers/tidy-data.html>

---
## Data: ... and the ugly

.reduite[.center[![](img/ugly1.png)]]

---
## Data: ... and the ugly (bis)

.reduite[.center[![](img/ugly2.png)]]

---

## Rendre les donn√©es exploitables pour la dataviz

Lisa Charlotte Rost: "How to prepare your data for analysis and charting in Excel & Google Sheets"

https://blog.datawrapper.de/prepare-and-clean-up-data-for-data-visualization/

---

## OpenRefine
<http://openrefine.org>

Outil de correction semi-automatique it√©ratif:

* travail par facettes/filtres

* heuristiques de clustering: collision de cl√©s, plus proches voisins (plusieurs variantes pour chacune)

* on s√©lectionne les fusions √† r√©aliser

* plus √©ventuellement donn√©es externes (wikidata)

=> Produire rapidement une version corrig√©e d'un jeu de donn√©es (corrections simples).

---

## Conclusion
* Les probl√®mes de qualit√© sont un frein majeur √† la publication et √† la r√©utilisation de donn√©es (ouvertes).

* Ils sont issus du **travail invisibilis√© de production des donn√©es**, dont on retrouve quelques traces dans la documentation et dans les donn√©es elles-m√™mes.

* L'exploitation de jeux de donn√©es "sales" n√©cessite leur nettoyage manuel ou semi-automatique (utilisation d'outils de correction comme OpenRefine)

---
class: inverse, center, middle

# Travailler avec des donn√©es non-structur√©es

---

## Donn√©es non structur√©es

* Fichiers textes et documents (.doc, .pdf, .html, .ppt)
* Courriels
* Donn√©es issues des r√©seaux sociaux
* Images
* Fichiers sons
* Vid√©os
* Logs de serveurs, sites, applications

Comment extraire les nombreuses informations contenues dans ces donn√©es non-structur√©es?

---
## Difficult√©s

.reduite[.center[![<https://xkcd.com/1425/>](./img/tasks.png)]]

<!-- In the 60s, Marvin Minsky assigned a couple of undergrads to spend the summer programming a computer to use a camera to identify objects in a scene. He figured they'd have the problem solved by the end of the summer. Half a century later, we're still working on it. -->

---
## Branches de l'IA

* Vision par ordinateur (Computer Vision)
  - d√©tection d'objet (Object Detection)
  - reconnaissance optique de caract√®res (Optical Character Recognition)

* Traitement automatique du langage naturel (Natural Language Processing)

Progr√®s de la recherche dans ces branches de l'IA => am√©lioration des performances des syst√®mes

---
## Panama papers

* 11.4 M fichiers, 2.6 To donn√©es
* "Soit plusieurs d√©cennies de lecture jour et nuit si l‚Äôon veut aller d‚Äôun bout √† l‚Äôautre de la base de donn√©es ‚Äì sans compter la complexit√© de certains dossiers."

.reduite[.center[![<https://www.lemonde.fr/panama-papers/article/2016/04/03/panama-papers-comment-le-monde-a-travaille-sur-plus-de-11-millions-de-fichiers_4894836_4890278.html>](img/lemonde-panama.png)]]

---
## Stack technique ICIJ

* extraction du texte par OCR avec Tesseract,
* recherche de termes avec Talend,
* indexation des r√©sultats avec Apache Solr,
* tokenization, filtrage, stemming, clustering de termes avec RapidMiner,
* classification automatique de documents avec RapidMiner.

<https://www.icij.org/blog/2018/08/how-machine-learning-is-revolutionizing-journalism/>

---
## Limites

* Donn√©es:
  - Fautes d'orthographe
  - Variations de la graphie
* Masse de donn√©es √† analyser:
  - Filtrer les documents peu int√©ressants,
  - Strat√©gies de classification plus √©labor√©e,
* Syst√®mes:
  - Erreurs d'OCR
  - Erreurs de NER
  - NB: erreurs en cascade => effet multiplicatif

---
## Data pipeline

.reduite[.center[![<https://xkcd.com/2054/>](img/data_pipeline.png)]]

---
## Named Entity Recognition

Sch√©ma d'annotation des dumps Wikipedia:

* PER:	Named person or family.
* LOC:	Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains).
* ORG:	Named corporate, governmental, or other organizational entity.
* MISC:	Miscellaneous entities, e.g. events, nationalities, products or works of art.

D'autres sch√©mas d'annotation plus d√©taill√©s existent.

Vous pouvez √©laborer vos propres sch√©mas d'annotation m√©tier, d√©riv√©s ou non de sch√©mas standard, et annoter des donn√©es.

---

## Annotation de donn√©es avec Prodigy

.reduite[.center[![](./img/prodigy.png)]]

<https://prodi.gy>

---

class: inverse, center, middle

# Workshop : Introduction √† la data visualisation

[datactivist
.coop/odl_paca](https://datactivist.coop/odl_paca)

---
class: center, middle, inverse

# Mod√©liser

---
## Pourquoi mod√©liser ?

.reduite[.center[![](./img/Hibbs.jpg)]]


---
## Pourquoi mod√©liser ? Les ["deux cultures"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)

- pour analyser et expliquer

- pour pr√©dire

---
## Pourquoi mod√©liser ? Les ["deux cultures"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)

- pour analyser et expliquer (**statistiques classiques, √©conom√©trie**)

- pour pr√©dire (**machine learning, IA...**)

---
## Mod√©liser pour analyser

- un mod√®le r√©duit de la r√©alit√©

- isoler le r√¥le de chaque variable

- raisonner "toutes choses √©gales par ailleurs" (*ceteris paribus*)

---
## Mod√©liser pour analyser

Mod√©liser, c‚Äôest mettre en relation une *variable expliqu√©e*
(d√©pendante / pr√©dite) et une ou plusieurs *variables explicatives*
(ind√©pendantes / pr√©dicteurs).

$$ Y = f(X_1, X_2, X_3, ..., X_n) $$

L‚Äôestimation du mod√®le consiste √† estimer la valeur des param√®tres
(ou coefficients). Le cas du mod√®le lin√©aire :

$$ Y = Œ± + Œ≤_1X_1 + Œ≤_2X_2 + Œ≤_3X_3 + ¬∑ ¬∑ ¬∑ + Œ≤_nX_n + Œµ $$

---
## Mod√©liser pour analyser

Implique de faire des hypoth√®ses sur la sp√©cification du mod√®le :

- variables explicatives

- distribution des erreurs

---
## Les distributions

- distribution th√©orique (ex : distribution normale)

- distribution empirique

http://shiny.stat.calpoly.edu/Prob_View/

---
## All models are wrong, some are useful

> Since all models are wrong the scientist cannot obtain a "correct" one by excessive elaboration. On the contrary following William of Occam he should seek an economical description of natural phenomena. 

[George Box](https://dx.doi.org/10.1080%2F01621459.1976.10480949)

---
## All models are wrong, some are useful

.reduite[.center[![](./img/ockham.jpg)]]

---
## Estimation d'un mod√®le

Dans le cas d'un mod√®le lin√©aire => m√©thode des moindres carr√©s ordinaires (MCO/OLS)

http://setosa.io/ev/ordinary-least-squares-regression/

---
## Attention !

- Les mod√®les de r√©gression lin√©aire supposent que les relations
sont *lin√©aires* et *additives*.

- Les *r√©sidus* sont suppos√©s √™tre *normalement distribu√©s*.

- Les coefficients ne sont *pas standardis√©s* (on ne peut pas les
comparer entre eux).

- Les coefficients s‚Äôinterpr√®tent *relativement √† l‚Äôunit√© de la variable d√©pendante*.

---
## Attention !

- Les coefficients estiment l‚Äôeffet d‚Äôune variable ind√©pendante
sur la variable d√©pendante *toutes choses √©gales par ailleurs*,
c‚Äôest-√†-dire en neutralisant l‚Äôeffet des autres variables.

- La qualit√© globale du mod√®le peut √™tre quantifi√© au travers du
$R^2$, qui repr√©sente la part de variance (de la variable
d√©pendante) expliqu√©e.

- Pour les variables ind√©pendantes cat√©goriques, on estime un
coefficient par modalit√©, √† l‚Äôexception de la premi√®re
(baseline).

---
## Mod√®les statistiques

Compromis entre intelligibilit√© et fid√©lit√© aux donn√©es

---
## Underfitting et overfitting

.reduite[.center[![](./img/underfit.png)]]

---
## Underfitting et overfitting

- diff√©rencier donn√©es d'apprentissage et donn√©es de test 

- n'utiliser les donn√©es de confirmation (test) qu'une fois 

---
## Extrapolation

[.reduite[.center[![](./img/sinus.png)]]](http://r4ds.had.co.nz/model-basics.html)

---
## Et le machine learning alors ?

- Fondamentalement, mod√©lisation et machine learning ne sont pas diff√©rents, du point de vue d'un statisticien : mod√©liser un $Y$ en fonction d'un vecteur de $X_i$

- une des diff√©rences principales toutefois : veut-on pr√©voir ou comprendre/analyser ?

- et donc : peut-on, veut-on interpr√©ter les coefficients ?

- en pratique : machine learning porte g√©n√©ralement sur des donn√©es plus complexes que la mod√©lisation traditionnelle

- souvent beaucoup de valeurs manquantes 

---
## Et le machine learning alors ?

.reduite[.center[![](./img/ratings.png)]]

---
## Concepts de machine learning

- Apprentissage supervis√© vs non supervis√© 

- Apprentissage supervis√© : il faut des donn√©es d√©j√† class√©es/√©talonn√©es. Souvent √† la main ! => *#digitallabour*

---
## Apprentissage supervis√© 

[.reduite[.center[![](./img/captcha.jpg)]]](https://fakecaptcha.com)

---
## Apprentissage supervis√©

[.reduite[.center[![](./img/opensolarmap.png)]]](https://cquest.hackpad.com/OpenSolarMap-9oMiYswLksF)

---
## Apprentissage supervis√©

[.reduite[.center[![](./img/inbox.png)]]](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf)

---
## Apprentissage non supervis√© 


- probl√®me majeur : r√©duction de la dimensionnalit√©

- jeux de donn√©es √† tr√®s haute dimensionnalit√© : impossible √† explorer visuellement. Comment simplifier l'information et la r√©sumer ?

.reduite[.center[![](./img/house.png)]]

---
## Apprentissage non supervis√© 

https://gallery.shinyapps.io/LDAelife/

---
class: inverse, center, middle

# Merci !

#<mathieu@datactivist.coop>

# √âvaluation de  la formation
